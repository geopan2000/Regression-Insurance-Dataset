{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# House Prices - Advanced Regression Techniques\n"
      ],
      "metadata": {
        "id": "9SRjmnakSrV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "sys.path.append('/content/drive/MyDrive')\n",
        "import utils\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAMwqpt8TVJk",
        "outputId": "8d44948c-871f-49c0-c73b-b98f6071c837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from utils import *\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "aS33fWEkUtpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "!pip install scikit-optimize\n",
        "!pip install shap\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold\n",
        "import shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR4fyrfxZBCz",
        "outputId": "f47472f3-3856-4cef-d4e3-60a5baeb30ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.9.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.46.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.5)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.1)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (3.1.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "qAv2ovzkTCrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/data/train.csv')\n",
        "data = data.drop('Id', axis=1)\n",
        "print(data)\n",
        "#print(data.info())\n",
        "\n",
        "#Separate the train set from the target variable\n",
        "train_price = data[['SalePrice']]\n",
        "train_data = data.drop('SalePrice', axis=1)\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/data/test.csv')\n",
        "ids_test = test_data['Id']\n",
        "test_data = test_data.drop('Id', axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8J6tqs3TCXZ",
        "outputId": "7aa9724d-80e5-4c2c-81c3-2fed96f613a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0             60       RL         65.0     8450   Pave   NaN      Reg   \n",
            "1             20       RL         80.0     9600   Pave   NaN      Reg   \n",
            "2             60       RL         68.0    11250   Pave   NaN      IR1   \n",
            "3             70       RL         60.0     9550   Pave   NaN      IR1   \n",
            "4             60       RL         84.0    14260   Pave   NaN      IR1   \n",
            "...          ...      ...          ...      ...    ...   ...      ...   \n",
            "1455          60       RL         62.0     7917   Pave   NaN      Reg   \n",
            "1456          20       RL         85.0    13175   Pave   NaN      Reg   \n",
            "1457          70       RL         66.0     9042   Pave   NaN      Reg   \n",
            "1458          20       RL         68.0     9717   Pave   NaN      Reg   \n",
            "1459          20       RL         75.0     9937   Pave   NaN      Reg   \n",
            "\n",
            "     LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
            "0            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
            "1            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
            "2            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
            "3            Lvl    AllPub    Corner  ...        0    NaN    NaN         NaN   \n",
            "4            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
            "...          ...       ...       ...  ...      ...    ...    ...         ...   \n",
            "1455         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
            "1456         Lvl    AllPub    Inside  ...        0    NaN  MnPrv         NaN   \n",
            "1457         Lvl    AllPub    Inside  ...        0    NaN  GdPrv        Shed   \n",
            "1458         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
            "1459         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
            "\n",
            "     MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
            "0          0      2    2008        WD         Normal     208500  \n",
            "1          0      5    2007        WD         Normal     181500  \n",
            "2          0      9    2008        WD         Normal     223500  \n",
            "3          0      2    2006        WD        Abnorml     140000  \n",
            "4          0     12    2008        WD         Normal     250000  \n",
            "...      ...    ...     ...       ...            ...        ...  \n",
            "1455       0      8    2007        WD         Normal     175000  \n",
            "1456       0      2    2010        WD         Normal     210000  \n",
            "1457    2500      5    2010        WD         Normal     266500  \n",
            "1458       0      4    2010        WD         Normal     142125  \n",
            "1459       0      6    2008        WD         Normal     147500  \n",
            "\n",
            "[1460 rows x 80 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforming Time related features"
      ],
      "metadata": {
        "id": "vm7RJMzzT991"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate age-related features\n",
        "train_data['HouseAge'] = train_data['YrSold'] - train_data['YearBuilt']\n",
        "train_data['RemodAge'] = train_data['YrSold'] - train_data['YearRemodAdd']\n",
        "train_data['GarageAge'] = train_data['YrSold'] - train_data['GarageYrBlt']\n",
        "\n",
        "test_data['HouseAge'] = test_data['YrSold'] - test_data['YearBuilt']\n",
        "test_data['RemodAge'] = test_data['YrSold'] - test_data['YearRemodAdd']\n",
        "test_data['GarageAge'] = test_data['YrSold'] - test_data['GarageYrBlt']\n",
        "\n",
        "# Drop the original year columns\n",
        "train_data = train_data.drop(['YearBuilt', 'YearRemodAdd', 'GarageYrBlt'], axis=1)\n",
        "test_data = test_data.drop(['YearBuilt', 'YearRemodAdd', 'GarageYrBlt'], axis=1)\n",
        "\n",
        "# Cyclical transformation for MoSold (Month Sold)\n",
        "train_data['sin_MoSold'] = np.sin(2 * np.pi * train_data['MoSold'] / 12)\n",
        "train_data['cos_MoSold'] = np.cos(2 * np.pi * train_data['MoSold'] / 12)\n",
        "\n",
        "test_data['sin_MoSold'] = np.sin(2 * np.pi * test_data['MoSold'] / 12)\n",
        "test_data['cos_MoSold'] = np.cos(2 * np.pi * test_data['MoSold'] / 12)\n",
        "\n",
        "# Drop the original MoSold column, as it's now represented by sin and cos\n",
        "train_data = train_data.drop('MoSold', axis=1)\n",
        "test_data = test_data.drop('MoSold', axis=1)\n",
        "\n",
        "# Optional: Time since a baseline year for YrSold\n",
        "baseline_year = 2000\n",
        "train_data['TimeSinceSold'] = train_data['YrSold'] - baseline_year\n",
        "test_data['TimeSinceSold'] = test_data['YrSold'] - baseline_year\n",
        "\n",
        "# Drop 'YrSold' if needed\n",
        "train_data = train_data.drop('YrSold', axis=1)\n",
        "test_data = test_data.drop('YrSold', axis=1)\n"
      ],
      "metadata": {
        "id": "Dj9CTBViT9j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of time-related features that should not be normalized\n",
        "time_features = ['HouseAge', 'RemodAge', 'GarageAge', 'TimeSinceSold', 'sin_MoSold', 'cos_MoSold', 'OverallQual','OverallCond','MSSubClass']  # Adjust this list if you have more\n",
        "\n",
        "# Identify the different types of variables\n",
        "object_columns = train_data.select_dtypes(include=['object']).columns\n",
        "int_columns = train_data.select_dtypes(include=['int64']).columns\n",
        "float_columns = train_data.select_dtypes(include=['float64']).columns\n",
        "\n",
        "# Combine int and float columns to be normalized, excluding the time-related features\n",
        "numeric_columns = [col for col in list(int_columns) + list(float_columns) if col not in time_features]\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data (numeric columns only)\n",
        "scaler.fit(train_data[numeric_columns])\n",
        "\n",
        "# Transform the numeric columns in the training and test data\n",
        "train_data[numeric_columns] = scaler.transform(train_data[numeric_columns])\n",
        "test_data[numeric_columns] = scaler.transform(test_data[numeric_columns])"
      ],
      "metadata": {
        "id": "DdChcyHEVkVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mappings for each ordinal feature\n",
        "ordinal_mappings = {\n",
        "    'GarageFinish': {'Fin': 3, 'RFn': 2, 'Unf': 1, 'NA': 0},\n",
        "    'ExterQual': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1},\n",
        "    'ExterCond': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1},\n",
        "    'PoolQC': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'NA': 0},\n",
        "    'Fence': {'GdPrv': 4, 'MnPrv': 3, 'GdWo': 2, 'MnWw': 1, 'NA': 0},\n",
        "    'GarageQual': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
        "    'GarageCond': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
        "    'FireplaceQu': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
        "    'HeatingQC': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1},\n",
        "    'KitchenQual': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1},\n",
        "    'LandSlope': {'Gtl': 3, 'Mod': 2, 'Sev': 1},\n",
        "    'BsmtQual': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
        "    'BsmtCond': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
        "    'BsmtExposure': {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0},\n",
        "    'BsmtFinType1': {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'NA': 0},\n",
        "    'BsmtFinType2': {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'NA': 0}\n",
        "}\n",
        "\n",
        "# Apply the mapping to train_data and test_data\n",
        "train_data = map_ordinal_features(train_data, ordinal_mappings)\n",
        "test_data = map_ordinal_features(test_data, ordinal_mappings)"
      ],
      "metadata": {
        "id": "8qtxnzORVntF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_mappings = {\n",
        "    'Street': {'Grvl': 0, 'Pave': 1},\n",
        "    'Alley': {'Grvl': 1, 'Pave': 2, 'NA': 0},\n",
        "    'CentralAir': {'N': 0, 'Y': 1},\n",
        "    'PavedDrive': {'N': 0, 'P': 1, 'Y': 2}\n",
        "}\n",
        "\n",
        "train_data = binary_encoding(train_data, binary_mappings)\n",
        "test_data = binary_encoding(test_data, binary_mappings)"
      ],
      "metadata": {
        "id": "gX6IdCl6VqA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of nominal features for one-hot encoding\n",
        "nominal_columns = ['MSZoning', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
        "                   'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
        "                   'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
        "                   'Foundation', 'Heating', 'Electrical', 'Functional', 'GarageType',\n",
        "                   'MiscFeature', 'SaleType', 'SaleCondition']\n",
        "print('Before One-Hot Encoding',train_data.shape)\n",
        "print('Before One-Hot Encoding',test_data.shape)\n",
        "# Apply one-hot encoding on train and test data\n",
        "train_data = pd.get_dummies(train_data, columns=nominal_columns)\n",
        "test_data = pd.get_dummies(test_data, columns=nominal_columns)\n",
        "\n",
        "# Align the columns of train and test data after one-hot encoding (important to avoid misalignment)\n",
        "train_data, test_data = train_data.align(test_data, join='left', axis=1)\n",
        "print('After One-Hot Encoding',train_data.shape)\n",
        "print('After One-Hot Encoding',test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9c46SFMV-AE",
        "outputId": "4cca8fb9-053c-40cd-8ae9-26ffc9f4ed1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before One-Hot Encoding (1460, 80)\n",
            "Before One-Hot Encoding (1459, 80)\n",
            "After One-Hot Encoding (1460, 229)\n",
            "After One-Hot Encoding (1459, 229)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.fillna(0, inplace=True)\n",
        "test_data.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "vgTdax0JW3ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what GPU is available in Google Colab\n",
        "!nvidia-smi\n",
        "\n",
        "# Log-transform the target variable\n",
        "price_log = np.log(train_price)\n",
        "\n",
        "# Define parameter search space\n",
        "search_spaces = {\n",
        "    'learning_rate': Real(0.001, 0.5, 'uniform'),\n",
        "    'max_depth': Integer(1, 70),\n",
        "    'n_estimators': Integer(100, 800),\n",
        "}\n",
        "\n",
        "# Initialize the XGBRegressor model with GPU support\n",
        "model = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    tree_method='gpu_hist',  # Use GPU for training\n",
        "    verbosity=2\n",
        ")\n",
        "\n",
        "kf = KFold(n_splits=10)  # 10-fold cross-validation\n",
        "\n",
        "# Using negative RMSE as the scoring metric\n",
        "optimizer = BayesSearchCV(\n",
        "    estimator=model,\n",
        "    search_spaces=search_spaces,\n",
        "    n_iter=64,\n",
        "    cv=kf,\n",
        "    scoring='neg_root_mean_squared_error',  # RMSE scoring\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# Fit the optimizer using X_train and log-transformed y_train\n",
        "optimizer.fit(train_data, price_log)\n",
        "\n",
        "# Get the best model\n",
        "best_model = optimizer.best_estimator_\n",
        "\n",
        "# Save the best model\n",
        "model_path = '/content/drive/MyDrive/data/XGB_1.json'\n",
        "best_model.save_model(model_path)\n",
        "\n",
        "# Get cross-validation errors\n",
        "cv_results = optimizer.cv_results_\n",
        "\n",
        "# Calculate and print the mean RMSE for each fold (convert negative RMSE back to positive)\n",
        "mean_rmse = -cv_results['mean_test_score']  # This is negative RMSE, so we negate it to get RMSE\n",
        "\n",
        "print(f\"Best parameters: {optimizer.best_params_}\")\n",
        "print(f\"Mean Cross-validation RMSE: {mean_rmse.mean():.4f}\")\n",
        "print(f\"Cross-validation RMSE for each iteration: {mean_rmse}\")\n",
        "\n",
        "print(\"Optimization complete. Best XGBoost model saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fut1h3ZFeZac",
        "outputId": "0ed0f86d-abf9-4291-84d4-8477c2a69ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 21 19:43:11 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   78C    P0              35W /  70W |    361MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [20:01:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: OrderedDict([('learning_rate', 0.17379598960219678), ('max_depth', 1), ('n_estimators', 800)])\n",
            "Mean Cross-validation RMSE: 0.1441\n",
            "Cross-validation RMSE for each iteration: [0.14867353 0.15439319 0.15635527 0.15008357 0.15595755 0.14913277\n",
            " 0.14603746 0.14558938 0.14851843 0.14995746 0.1478415  0.13711305\n",
            " 0.12250037 0.12223658 0.12151542 0.22852083 0.15637727 0.12278206\n",
            " 0.23855627 0.12995254 0.36962345 0.14354801 0.12376342 0.12536379\n",
            " 0.14762268 0.12190767 0.13710334 0.13551159 0.13711595 0.12146636\n",
            " 0.14739707 0.1232596  0.12099542 0.12700137 0.15647132 0.14569983\n",
            " 0.13681333 0.12096653 0.15004862 0.12189518 0.14457065 0.15651156\n",
            " 0.15018764 0.12204164 0.12193031 0.14785522 0.12684956 0.12132789\n",
            " 0.12278792 0.14781197 0.12157715 0.12240428 0.15566704 0.12180245\n",
            " 0.12084234 0.14599974 0.13556061 0.14912456 0.14571546 0.14717737\n",
            " 0.12408788 0.14927759 0.12201216 0.15633012]\n",
            "Optimization complete. Best XGBoost model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [20:01:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert test data to DMatrix\n",
        "dtest = xgb.DMatrix(test_data)\n",
        "\n",
        "# Load the trained model\n",
        "model_path = f'/content/drive/MyDrive/data/XGB_1.json'\n",
        "model = xgb.Booster(model_file=model_path)\n",
        "\n",
        "# Get predictions\n",
        "preds_log = model.predict(dtest)\n",
        "\n",
        "# Convert log-transformed predictions back to original scale\n",
        "preds = np.exp(preds_log)\n",
        "\n",
        "# Ensure the length of predictions matches the number of rows in the test data\n",
        "assert len(preds) == len(ids_test), \"Mismatch between number of predictions and test data IDs\"\n",
        "\n",
        "# Create output DataFrame with original Id and predicted SalePrice\n",
        "output = pd.DataFrame({'Id': ids_test, 'SalePrice': preds.squeeze()})\n",
        "\n",
        "# Remove any duplicate rows by 'Id'\n",
        "output.drop_duplicates(subset='Id', keep='first', inplace=True)\n",
        "\n",
        "output.to_csv('/content/drive/MyDrive/data/predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "te10JEHfdFVE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}